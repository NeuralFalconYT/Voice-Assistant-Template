{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O-4TSIGE1Bd_"
      },
      "outputs": [],
      "source": [
        "!pip install gradio==4.36.1\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_any_model(system_role,user_msg):\n",
        "  response=user_msg\n",
        "  return response\n",
        "system_role= \"You are a helpful AI assistant.\"  # @param {type: \"string\"}\n",
        "user_msg = \"Who are you?\"  # @param {type: \"string\"}\n",
        "llm_reply=run_any_model(system_role,user_msg)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(llm_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GQ2M1G1f1XrA",
        "outputId": "db34f79d-d28e-426a-d3c6-fe03a825b34e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Gradio API Interface\n",
        "username = 'admin'  # @param {type: \"string\"}\n",
        "password = 'admin'  # @param {type: \"string\"}\n",
        "Debug = True  # @param {type: \"boolean\"}\n",
        "\n",
        "import gradio as gr\n",
        "gradio_examples = [[\"You are a helpful AI assistant.\",\"Who are you?\"]]\n",
        "gradio_input=[gr.Textbox(label=\"System Role\"),gr.Textbox(label=\"User Message\")]\n",
        "gradio_output=[gr.Textbox(label=\"LLM Response\")]\n",
        "gradio_interface = gr.Interface(fn=run_any_model, inputs=gradio_input,outputs=gradio_output , title=\"LLM Model\",examples=gradio_examples)\n",
        "gradio_interface.queue().launch(share=True,debug=Debug,auth=(username, password))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "cellView": "form",
        "id": "9AUXeoxH1Lb2",
        "outputId": "f13b9d43-cd80-4c1b-e19a-da8dfedfd378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://095ed9db62733d8208.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://095ed9db62733d8208.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}